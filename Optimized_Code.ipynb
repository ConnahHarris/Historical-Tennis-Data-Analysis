{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b972378f-baf6-460a-aa01-76ef609af6c8",
   "metadata": {},
   "source": [
    "# Useful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46fd9273-030d-40c6-b753-2a27aa42ab83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_p1_sameplayer(dataframe, p1_id, p2_id):\n",
    "   \n",
    "    # Creates new dataframe with match data between p1 and p2\n",
    "    df_h2h = dataframe[((dataframe['p1_id'] == p1_id) | (dataframe['p2_id'] == p1_id)) & ((dataframe['p1_id'] == p2_id) | (dataframe['p2_id'] == p2_id))].copy()\n",
    "    df_h2h['result'] = 1\n",
    "    \n",
    "    # Creates list of column names\n",
    "    col_list = dataframe.columns\n",
    "    \n",
    "    # Empty list of columns to swap \n",
    "    cols_to_swap = []\n",
    "    \n",
    "    # Finds which columns to swap\n",
    "    for col in col_list:\n",
    "        if str(col).startswith('p1_'):\n",
    "            suffix = col[3:]\n",
    "            matching_col = 'p2_' + suffix\n",
    "            if matching_col in col_list:\n",
    "                cols_to_swap.append((col, matching_col))\n",
    "    \n",
    "    # Swap mask condition\n",
    "    swap_mask = ~((df_h2h['p1_id'] == p2_id) | (df_h2h['p2_id'] == p1_id))\n",
    "    \n",
    "    # Swaps columns\n",
    "    for col1, col2 in cols_to_swap:\n",
    "        temp = df_h2h.loc[swap_mask, col1].copy()\n",
    "        df_h2h.loc[swap_mask, col1] = df_h2h.loc[swap_mask, col2]\n",
    "        df_h2h.loc[swap_mask, col2] = temp\n",
    "    \n",
    "    df_h2h.loc[swap_mask, \"result\"] = 0     \n",
    "\n",
    "    return df_h2h.head(30)\n",
    "\n",
    "#make_p1_sameplayer(df_subset, 104925, 103819)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6062848-304a-475a-a9c9-5ca01c650380",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_player(dataframe, p1_id):\n",
    "   \n",
    "    # Creates new dataframe with match data between p1 and p2\n",
    "    df_player = dataframe[((dataframe['p1_id'] == p1_id) | (dataframe['p2_id'] == p1_id))].copy()\n",
    "    \n",
    "    # Creates list of column names\n",
    "    col_list = dataframe.columns\n",
    "    \n",
    "    # Empty list of columns to swap \n",
    "    cols_to_swap = []\n",
    "    \n",
    "    # Finds which columns to swap\n",
    "    for col in col_list:\n",
    "        if str(col).startswith('p1_'):\n",
    "            suffix = col[3:]\n",
    "            matching_col = 'p2_' + suffix\n",
    "            if matching_col in col_list:\n",
    "                cols_to_swap.append((col, matching_col))\n",
    "    \n",
    "    # Swap mask condition\n",
    "    swap_mask = ~((df_player['p1_id'] == p1_id))\n",
    "    \n",
    "    # Swaps columns\n",
    "    for col1, col2 in cols_to_swap:\n",
    "        temp = df_player.loc[swap_mask, col1].copy()\n",
    "        df_player.loc[swap_mask, col1] = df_player.loc[swap_mask, col2]\n",
    "        df_player.loc[swap_mask, col2] = temp   \n",
    "\n",
    "    return df_player\n",
    "\n",
    "#df_player(df_subset, 104925)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c45391-7a5b-4170-9cbe-06904ce86986",
   "metadata": {},
   "source": [
    "# Cleaning and Reducing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d73810c2-b73e-48a3-8e2d-ad414775797e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "# Display all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Display all rows\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "\n",
    "# Reads all csv files in this folder and concatinates them\n",
    "csv_files = glob.glob('*.csv')\n",
    "df_list = [pd.read_csv(file) for file in csv_files]\n",
    "df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "\n",
    "# Rename useful columns\n",
    "df.rename(columns={\"tourney_id\": \"tournament_id\"}, inplace=True)\n",
    "df.rename(columns={\"tourney_name\": \"tournament_name\"}, inplace=True)\n",
    "df.rename(columns={\"tourney_date\": \"tournament_date\"}, inplace=True)\n",
    "df.rename(columns={\"winner_ht\": \"p1_height\"}, inplace=True)\n",
    "df.rename(columns={\"winner_id\": \"p1_id\"}, inplace=True)\n",
    "df.rename(columns={\"winner_name\": \"p1_name\"}, inplace=True)\n",
    "df.rename(columns={\"winner_age\": \"p1_age\"}, inplace=True)\n",
    "df.rename(columns={\"loser_age\": \"p2_age\"}, inplace=True)\n",
    "df.rename(columns={\"winner_hand\": \"p1_hand\"}, inplace=True)\n",
    "df.rename(columns={\"loser_ht\": \"p2_height\"}, inplace=True)\n",
    "df.rename(columns={\"loser_id\": \"p2_id\"}, inplace=True)\n",
    "df.rename(columns={\"loser_name\": \"p2_name\"}, inplace=True)\n",
    "df.rename(columns={\"loser_hand\": \"p2_hand\"}, inplace=True)\n",
    "\n",
    "# Create subset of dataframe with useful columns\n",
    "df_subset = df[['tournament_date','tournament_name', 'surface', 'p1_name', 'p1_id', 'p1_age', 'p1_height', 'p2_name', 'p2_id', 'p2_age', 'p2_height']]\n",
    "\n",
    "# Remove rows with NaN values for surface column\n",
    "df_subset = df_subset.dropna(subset=['surface'])\n",
    "df_subset = df_subset.dropna(subset=['p1_age'])\n",
    "df_subset = df_subset.dropna(subset=['p2_age'])\n",
    "df_subset = df_subset.dropna(subset=['p1_height'])\n",
    "df_subset = df_subset.dropna(subset=['p2_height'])\n",
    "\n",
    "# Sort rows by tournament date\n",
    "df_subset = df_subset.sort_values(by='tournament_date')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120cfcd5-53af-4ecd-b5f4-66090029ea20",
   "metadata": {},
   "source": [
    "# Adding Difference Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b12bee-e6cc-47a3-8011-44e960a749b9",
   "metadata": {},
   "source": [
    "#### Player Age - Cleaning age data (did not remove any data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e78255a-3d74-45ea-8d87-fec2c6ed40c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_subset['p1_age'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33a8638a-edf0-4b5d-86f2-d861a8af60f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_subset[(df_subset['p1_age'] >= 40) | (df_subset['p2_age'] >= 40)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7919628f-23a3-4d32-a063-a16391d642cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty lists to store age differences\n",
    "p1_age_diff_list = []\n",
    "p2_age_diff_list = []\n",
    "\n",
    "# loops over the age columns and calculates players age difference\n",
    "for p1, p2 in zip(df_subset['p1_age'], df_subset['p2_age']):\n",
    "    p1_age_diff = p1 - p2\n",
    "    p2_age_diff = p2 - p1\n",
    "\n",
    "    # Adds calculated age differences to list\n",
    "    p1_age_diff_list.append(p1_age_diff)\n",
    "    p2_age_diff_list.append(p2_age_diff)\n",
    "\n",
    "# Assign df columns\n",
    "df_subset['p1_age_diff'] = p1_age_diff_list\n",
    "df_subset['p2_age_diff'] = p2_age_diff_list\n",
    "\n",
    "#df_subset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1026c829-c22f-4e2a-9a0b-274309c0c0ec",
   "metadata": {},
   "source": [
    "#### Player Height - Cleaning height data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b5002c7-e96e-4543-b303-d19bed1aba81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_subset['p1_height'].describe()\n",
    "#df_subset['p2_height'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b55f6d8-f3b8-4315-858b-3f90e35650f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find anomolously short players\n",
    "#max_height = 75\n",
    "#new_subset = df_subset[(df_subset['p1_height'] <= max_height) | (df_subset['p2_height'] <= max_height)]\n",
    "\n",
    "# Find anomolously tall players\n",
    "#min_height = 211\n",
    "#df_subset[(df_subset['p1_height'] >= min_height) | (df_subset['p2_height'] >= min_height)]\n",
    "\n",
    "\n",
    "#List of anomalous players to remove\n",
    "anom_heights_list = ['Jorge Brian Panta Herreros',\n",
    "'Johannes Ingildsen',\n",
    "'Viacheslav Bielinskyi'\t                     \n",
    "]\n",
    "\n",
    "\n",
    "# remove anomalous players\n",
    "for name in anom_heights_list:\n",
    "    if (df_subset == name).any().any():\n",
    "        df_subset = df_subset[~df_subset.isin([name]).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85ef1004-fcc4-4bb0-943f-1271af9e43ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty lists to store height differences\n",
    "p1_height_diff_list = []\n",
    "p2_height_diff_list = []\n",
    "\n",
    "# loops over the age columns and calculates players height difference\n",
    "for p1, p2 in zip(df_subset['p1_height'], df_subset['p2_height']):\n",
    "    p1_height_diff = p1 - p2\n",
    "    p2_height_diff = p2 - p1\n",
    "\n",
    "    # Adds calculated age differences to list\n",
    "    p1_height_diff_list.append(p1_height_diff)\n",
    "    p2_height_diff_list.append(p2_height_diff)\n",
    "\n",
    "# Assign df columns\n",
    "df_subset['p1_height_diff'] = p1_height_diff_list\n",
    "df_subset['p2_height_diff'] = p2_height_diff_list\n",
    "\n",
    "#df_subset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58bfc48-1ef9-47c9-b3b8-ab8fdfeacf37",
   "metadata": {},
   "source": [
    "# Calculating Previous Wins Against Opponent Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c63e66ac-f7f3-4dda-a87a-56f9e2d690da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary that stores head-to-head match results. Returns 0 if the key does not exist (players have never played before)\n",
    "h2h_wins_dict = defaultdict(int)\n",
    "h2h_history_dict = defaultdict(list)\n",
    "\n",
    "# Stores immediate results\n",
    "p1_h2h_wins_before = []\n",
    "p2_h2h_wins_before = []\n",
    "\n",
    "p1_h2h_wins_total_diff_before = []\n",
    "p2_h2h_wins_total_diff_before = []\n",
    "\n",
    "p1_h2h_wins_last1_diff_before = []\n",
    "p2_h2h_wins_last1_diff_before = []\n",
    "\n",
    "p1_h2h_wins_last2_diff_before = []\n",
    "p2_h2h_wins_last2_diff_before = []\n",
    "\n",
    "p1_h2h_wins_last3_diff_before = []\n",
    "p2_h2h_wins_last3_diff_before = []\n",
    "\n",
    "p1_h2h_wins_last4_diff_before = []\n",
    "p2_h2h_wins_last4_diff_before = []\n",
    "\n",
    "p1_h2h_wins_last5_diff_before = []\n",
    "p2_h2h_wins_last5_diff_before = []\n",
    "\n",
    "p1_h2h_wins_last10_diff_before = []\n",
    "p2_h2h_wins_last10_diff_before = []\n",
    "\n",
    "\n",
    "# Iterate through each match in df_subset, returning player_ids as pairs i.e [(100,200), (300, 250)...]  \n",
    "for p1, p2 in zip(df_subset['p1_id'], df_subset['p2_id']):\n",
    "    \n",
    "    # Creates keys for head-to-head matches\n",
    "    wins_key1 = (p1, p2)\n",
    "    wins_key2 = (p2, p1)\n",
    "    wins_match_key = tuple(sorted([p1, p2]))\n",
    "\n",
    "    # Gets wins before this match\n",
    "    p1_h2h_wins = h2h_wins_dict[wins_key1]\n",
    "    p2_h2h_wins = h2h_wins_dict[wins_key2]\n",
    "    \n",
    "    # Saves wins to px_h2h_wins_before lists to then be used for dataframe columns\n",
    "    p1_h2h_wins_before.append(p1_h2h_wins)\n",
    "    p2_h2h_wins_before.append(p2_h2h_wins)\n",
    "    \n",
    "    # Calculates wins difference\n",
    "    p1_h2h_wins_diff = p1_h2h_wins - p2_h2h_wins\n",
    "    p2_h2h_wins_diff = p2_h2h_wins - p1_h2h_wins\n",
    "    \n",
    "    # Saves differences to px_h2h_wins_diff_before lists to then be used for dataframe columns\n",
    "    p1_h2h_wins_total_diff_before.append(p1_h2h_wins_diff)\n",
    "    p2_h2h_wins_total_diff_before.append(p2_h2h_wins_diff)\n",
    "\n",
    "    #\n",
    "    history_last1 = h2h_history_dict[wins_match_key][-1:]\n",
    "    p1_last1_wins = history_last1.count(p1)\n",
    "    p2_last1_wins = history_last1.count(p2)\n",
    "    p1_last1_diff = p1_last1_wins - p2_last1_wins\n",
    "    p2_last1_diff = p2_last1_wins - p1_last1_wins\n",
    "    p1_h2h_wins_last1_diff_before.append(p1_last1_diff)\n",
    "    p2_h2h_wins_last1_diff_before.append(p2_last1_diff)\n",
    "    \n",
    "    history_last2 = h2h_history_dict[wins_match_key][-2:]\n",
    "    p1_last2_wins = history_last2.count(p1)\n",
    "    p2_last2_wins = history_last2.count(p2)\n",
    "    p1_last2_diff = p1_last2_wins - p2_last2_wins\n",
    "    p2_last2_diff = p2_last2_wins - p1_last2_wins\n",
    "    p1_h2h_wins_last2_diff_before.append(p1_last2_diff)\n",
    "    p2_h2h_wins_last2_diff_before.append(p2_last2_diff)\n",
    "    \n",
    "    history_last3 = h2h_history_dict[wins_match_key][-3:]\n",
    "    p1_last3_wins = history_last3.count(p1)\n",
    "    p2_last3_wins = history_last3.count(p2)\n",
    "    p1_last3_diff = p1_last3_wins - p2_last3_wins\n",
    "    p2_last3_diff = p2_last3_wins - p1_last3_wins\n",
    "    p1_h2h_wins_last3_diff_before.append(p1_last3_diff)\n",
    "    p2_h2h_wins_last3_diff_before.append(p2_last3_diff)\n",
    "\n",
    "    history_last4 = h2h_history_dict[wins_match_key][-4:]\n",
    "    p1_last4_wins = history_last4.count(p1)\n",
    "    p2_last4_wins = history_last4.count(p2)\n",
    "    p1_last4_diff = p1_last4_wins - p2_last4_wins\n",
    "    p2_last4_diff = p2_last4_wins - p1_last4_wins\n",
    "    p1_h2h_wins_last4_diff_before.append(p1_last4_diff)\n",
    "    p2_h2h_wins_last4_diff_before.append(p2_last4_diff)\n",
    "    \n",
    "    history_last5 = h2h_history_dict[wins_match_key][-5:]\n",
    "    p1_last5_wins = history_last5.count(p1)\n",
    "    p2_last5_wins = history_last5.count(p2)\n",
    "    p1_last5_diff = p1_last5_wins - p2_last5_wins\n",
    "    p2_last5_diff = p2_last5_wins - p1_last5_wins\n",
    "    p1_h2h_wins_last5_diff_before.append(p1_last5_diff)\n",
    "    p2_h2h_wins_last5_diff_before.append(p2_last5_diff)\n",
    "\n",
    "    history_last10 = h2h_history_dict[wins_match_key][-10:]\n",
    "    p1_last10_wins = history_last10.count(p1)\n",
    "    p2_last10_wins = history_last10.count(p2)\n",
    "    p1_last10_diff = p1_last10_wins - p2_last10_wins\n",
    "    p2_last10_diff = p2_last10_wins - p1_last10_wins\n",
    "    p1_h2h_wins_last10_diff_before.append(p1_last10_diff)\n",
    "    p2_h2h_wins_last10_diff_before.append(p2_last10_diff)\n",
    "\n",
    "    # Player 1 always wins in this df_subset, updates head-to-head\n",
    "    h2h_wins_dict[wins_key1] += 1  \n",
    "\n",
    "    # Updates h2h history dicitonary \n",
    "    h2h_history_dict[wins_match_key].append(p1)\n",
    "\n",
    "# Assign to dataframe\n",
    "df_subset['p1_h2h_wins'] = p1_h2h_wins_before\n",
    "df_subset['p2_h2h_wins'] = p2_h2h_wins_before\n",
    "df_subset['p1_h2h_wins_before_total_diff'] = p1_h2h_wins_total_diff_before\n",
    "df_subset['p2_h2h_wins_before_total_diff'] = p2_h2h_wins_total_diff_before\n",
    "df_subset['p1_h2h_wins_before_last1_diff'] = p1_h2h_wins_last1_diff_before\n",
    "df_subset['p2_h2h_wins_before_last1_diff'] = p2_h2h_wins_last1_diff_before\n",
    "df_subset['p1_h2h_wins_before_last2_diff'] = p1_h2h_wins_last2_diff_before\n",
    "df_subset['p2_h2h_wins_before_last2_diff'] = p2_h2h_wins_last2_diff_before\n",
    "df_subset['p1_h2h_wins_before_last3_diff'] = p1_h2h_wins_last3_diff_before\n",
    "df_subset['p2_h2h_wins_before_last3_diff'] = p2_h2h_wins_last3_diff_before\n",
    "df_subset['p1_h2h_wins_before_last4_diff'] = p1_h2h_wins_last4_diff_before\n",
    "df_subset['p2_h2h_wins_before_last4_diff'] = p2_h2h_wins_last4_diff_before\n",
    "df_subset['p1_h2h_wins_before_last5_diff'] = p1_h2h_wins_last5_diff_before\n",
    "df_subset['p2_h2h_wins_before_last5_diff'] = p2_h2h_wins_last5_diff_before\n",
    "df_subset['p1_h2h_wins_before_last10_diff'] = p1_h2h_wins_last10_diff_before\n",
    "df_subset['p2_h2h_wins_before_last10_diff'] = p2_h2h_wins_last10_diff_before"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b2a19a-0481-4ce4-b21e-ef35ebc098dd",
   "metadata": {},
   "source": [
    "# Calculating ELO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab316383-a868-4c0f-a9e0-a559d9e0bf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary that stores players ELO. Returns 1500 if the key does not exist (player has not played before)\n",
    "elo_dict = defaultdict(lambda: 1500)\n",
    "\n",
    "# Stores immediate elo\n",
    "p1_elo_before = []\n",
    "p2_elo_before = []\n",
    "\n",
    "# Iterate through each match in df_subset, returning player_ids as pairs i.e [(100,200), (300, 250)...]  \n",
    "for p1, p2 in zip(df_subset['p1_id'], df_subset['p2_id']):\n",
    "    elo_key1 = p1\n",
    "    elo_key2 = p2\n",
    "\n",
    "    # Checks dictionary for ELO and stores the ELO as px_elo\n",
    "    p1_elo = elo_dict[elo_key1]\n",
    "    p2_elo = elo_dict[elo_key2]\n",
    "\n",
    "    # Adds ELO to the list px_elo_before\n",
    "    p1_elo_before.append(p1_elo)\n",
    "    p2_elo_before.append(p2_elo)\n",
    "\n",
    "    # Calculates expected score\n",
    "    p1_expected_score = 1 / (1 + 10**((p2_elo - p1_elo)/400))\n",
    "    p2_expected_score = 1 / (1 + 10**((p1_elo - p2_elo)/400))\n",
    "\n",
    "    # Calculates ELO after the match\n",
    "    K = 32\n",
    "    p1_elo_after = int(p1_elo + K * (1 - p1_expected_score))\n",
    "    p2_elo_after = int(p2_elo + K * (0 - p2_expected_score))  # Fixed this line\n",
    "\n",
    "    # Stores new ELO in the dictionary\n",
    "    elo_dict[elo_key1] = p1_elo_after\n",
    "    elo_dict[elo_key2] = p2_elo_after\n",
    "    \n",
    "# Assign to dataframe\n",
    "df_subset['p1_elo_before'] = p1_elo_before\n",
    "df_subset['p2_elo_before'] = p2_elo_before"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388959ed-caf6-4c5a-8897-c63e8982c18d",
   "metadata": {},
   "source": [
    "#### Calculating ELO difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b02a69f-57f7-406a-bf24-e123533fafad",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1_elo_diff_list = []\n",
    "p2_elo_diff_list = []\n",
    "\n",
    "for p1, p2 in zip(df_subset['p1_elo_before'], df_subset['p2_elo_before']):\n",
    "    p1_elo_diff = p1 - p2\n",
    "    p2_elo_diff = p2 - p1\n",
    "\n",
    "    p1_elo_diff_list.append(p1_elo_diff)\n",
    "    p2_elo_diff_list.append(p2_elo_diff)\n",
    "\n",
    "df_subset['p1_elo_diff_before'] = p1_elo_diff_list\n",
    "df_subset['p2_elo_diff_before'] = p2_elo_diff_list\n",
    "\n",
    "#df_subset.head(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cff8fbf-1801-4e68-9f62-416d654cbf66",
   "metadata": {},
   "source": [
    "#### Sum of Surfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f62ebf51-a954-404a-bdd9-e466a68297d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "surface_dict = {}\n",
    "\n",
    "for surface in df_subset['surface']:\n",
    "    surface_dict[surface] = surface_dict.get(surface, 0) + 1\n",
    "\n",
    "#print(surface_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6763ccdb-cb08-4446-87d6-cecd452add56",
   "metadata": {},
   "source": [
    "#### Calculating surface ELO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d51c37f6-dfc2-47f3-a7d3-ce510040ade5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# 1. Create a nested defaultdict: elo_dict[player_id][surface] = ELO\n",
    "elo_dict = defaultdict(lambda: defaultdict(lambda: 1500))\n",
    "\n",
    "# 2. Lists to store ELOs before the match\n",
    "p1_surface_elo_before = []\n",
    "p2_surface_elo_before = []\n",
    "\n",
    "# 3. Loop through df_subset row by row\n",
    "for surface, p1, p2 in zip(df_subset['surface'], df_subset['p1_id'], df_subset['p2_id']):\n",
    "    \n",
    "    p1_elo = elo_dict[p1][surface]\n",
    "    p2_elo = elo_dict[p2][surface]\n",
    "\n",
    "    # Store ELOs before match\n",
    "    p1_surface_elo_before.append(p1_elo)\n",
    "    p2_surface_elo_before.append(p2_elo)\n",
    "\n",
    "    # Calculate expected scores\n",
    "    p1_expected = 1 / (1 + 10 ** ((p2_elo - p1_elo) / 400))\n",
    "    p2_expected = 1 / (1 + 10 ** ((p1_elo - p2_elo) / 400))\n",
    "\n",
    "    # Update ELOs assuming p1 wins\n",
    "    K = 32\n",
    "    elo_dict[p1][surface] = int(p1_elo + K * (1 - p1_expected))\n",
    "    elo_dict[p2][surface] = int(p2_elo + K * (0 - p2_expected))\n",
    "\n",
    "# 4. Add columns to df_subset\n",
    "df_subset['p1_surface_elo_before'] = p1_surface_elo_before\n",
    "df_subset['p2_surface_elo_before'] = p2_surface_elo_before"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfc9c62-2dee-4e06-ba9e-20e99ef48269",
   "metadata": {},
   "source": [
    "#### Calculating surface ELO difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23eede08-967d-4ba7-922c-26d67529a9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1_surface_elo_diff_list = []\n",
    "p2_surface_elo_diff_list = []\n",
    "\n",
    "for p1, p2 in zip(df_subset['p1_surface_elo_before'], df_subset['p2_surface_elo_before']):\n",
    "    p1_surface_elo_diff = p1 - p2\n",
    "    p2_surface_elo_diff = p2 - p1\n",
    "\n",
    "    p1_surface_elo_diff_list.append(p1_surface_elo_diff)\n",
    "    p2_surface_elo_diff_list.append(p2_surface_elo_diff)\n",
    "\n",
    "df_subset['p1_surface_elo_diff_before'] = p1_surface_elo_diff_list\n",
    "df_subset['p2_surface_elo_diff_before'] = p2_surface_elo_diff_list\n",
    "\n",
    "#df_subset.head(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eeaeb62-1a48-4a6a-bfb9-14fafd9ae178",
   "metadata": {},
   "source": [
    "# Calculating Total Number of matches a Player Has Played"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9bcaddea-29f7-4951-9c12-f90760b985df",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_matches_dict = defaultdict(int)\n",
    "\n",
    "p1_total_matches_before = []\n",
    "p2_total_matches_before = []\n",
    "\n",
    "for p1, p2 in zip(df_subset['p1_id'], df_subset['p2_id']):\n",
    "    total_matches_key1 = p1\n",
    "    total_matches_key2 = p2\n",
    "\n",
    "    p1_total_matches = total_matches_dict[total_matches_key1]\n",
    "    p2_total_matches = total_matches_dict[total_matches_key2]\n",
    "\n",
    "    p1_total_matches_before.append(p1_total_matches)\n",
    "    p2_total_matches_before.append(p2_total_matches)\n",
    "\n",
    "    p1_total_matches_after = p1_total_matches + 1\n",
    "    p2_total_matches_after = p2_total_matches + 1\n",
    "\n",
    "    total_matches_dict[total_matches_key1] = p1_total_matches_after\n",
    "    total_matches_dict[total_matches_key2] = p2_total_matches_after\n",
    "\n",
    "df_subset['p1_total_matches_before'] = p1_total_matches_before\n",
    "df_subset['p2_total_matches_before'] = p2_total_matches_before"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4305b6-4b29-407a-a759-0f73b29163b6",
   "metadata": {},
   "source": [
    "#### Calculate total matches player difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72966928-f359-49df-a762-effc27009c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1_total_career_matches_diff_list = []\n",
    "p2_total_career_matches_diff_list = []\n",
    "\n",
    "for p1, p2 in zip(df_subset['p1_total_matches_before'], df_subset['p2_total_matches_before']):\n",
    "    p1_career_matches_diff = p1 - p2\n",
    "    p2_career_matches_diff = p2 - p1\n",
    "\n",
    "    p1_total_career_matches_diff_list.append(p1_career_matches_diff)\n",
    "    p2_total_career_matches_diff_list.append(p2_career_matches_diff)\n",
    "\n",
    "df_subset['p1_total_matches_before_diff'] = p1_total_career_matches_diff_list\n",
    "df_subset['p2_total_matches_before_diff'] = p2_total_career_matches_diff_list\n",
    "\n",
    "#df_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f07b01d-3ed6-4acb-b623-9203888f0be3",
   "metadata": {},
   "source": [
    "# Calculating Total Wins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0eebc64-9404-43eb-84b3-b57655f6c392",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Initialize\n",
    "career_wins_dict = defaultdict(int)\n",
    "career_wins_history_dict = defaultdict(list)\n",
    "\n",
    "# Lists to store computed features\n",
    "p1_career_wins_before = []\n",
    "p2_career_wins_before = []\n",
    "\n",
    "p1_career_wins_last3_pct_before = []\n",
    "p2_career_wins_last3_pct_before = []\n",
    "\n",
    "p1_career_wins_last5_pct_before = []\n",
    "p2_career_wins_last5_pct_before = []\n",
    "\n",
    "p1_career_wins_last10_pct_before = []\n",
    "p2_career_wins_last10_pct_before = []\n",
    "\n",
    "x1 = 3\n",
    "x2 = 5\n",
    "x3 = 10\n",
    "\n",
    "for p1, p2 in zip(df_subset['p1_id'], df_subset['p2_id']):\n",
    "    # Store total wins before this match\n",
    "    p1_career_wins_before.append(career_wins_dict[p1])\n",
    "    p2_career_wins_before.append(career_wins_dict[p2])\n",
    "\n",
    "    # Get last 3 outcomes\n",
    "    p1_last3 = career_wins_history_dict[p1][-x1:]\n",
    "    p2_last3 = career_wins_history_dict[p2][-x1:]\n",
    "\n",
    "    # Get last 5 outcomes\n",
    "    p1_last5 = career_wins_history_dict[p1][-x2:]\n",
    "    p2_last5 = career_wins_history_dict[p2][-x2:]\n",
    "\n",
    "    # Get last 10 outcomes\n",
    "    p1_last10 = career_wins_history_dict[p1][-x3:]\n",
    "    p2_last10 = career_wins_history_dict[p2][-x3:]\n",
    "\n",
    "    # Compute recent win % (if enough history)\n",
    "    p1_last3_pct = round((sum(p1_last3) / x1) * 100, 1) if len(p1_last3) == x1 else 0\n",
    "    p2_last3_pct = round((sum(p2_last3) / x1) * 100, 1) if len(p2_last3) == x1 else 0\n",
    "\n",
    "    # Compute recent win % (if enough history)\n",
    "    p1_last5_pct = round((sum(p1_last5) / x2) * 100, 1) if len(p1_last5) == x2 else 0\n",
    "    p2_last5_pct = round((sum(p2_last5) / x2) * 100, 1) if len(p2_last5) == x2 else 0\n",
    "\n",
    "    # Compute recent win % (if enough history)\n",
    "    p1_last10_pct = round((sum(p1_last10) / x3) * 100, 1) if len(p1_last10) == x3 else 0\n",
    "    p2_last10_pct = round((sum(p2_last10) / x3) * 100, 1) if len(p2_last10) == x3 else 0\n",
    "\n",
    "    \n",
    "    p1_career_wins_last3_pct_before.append(p1_last3_pct)\n",
    "    p2_career_wins_last3_pct_before.append(p2_last3_pct)\n",
    "\n",
    "    p1_career_wins_last5_pct_before.append(p1_last5_pct)\n",
    "    p2_career_wins_last5_pct_before.append(p2_last5_pct)\n",
    "\n",
    "    p1_career_wins_last10_pct_before.append(p1_last10_pct)\n",
    "    p2_career_wins_last10_pct_before.append(p2_last10_pct)\n",
    "\n",
    "    \n",
    "    # Update total wins\n",
    "    career_wins_dict[p1] += 1\n",
    "\n",
    "    # Update recent win/loss history\n",
    "    career_wins_history_dict[p1].append(1)  # p1 won\n",
    "    career_wins_history_dict[p2].append(0)  # p2 lost\n",
    "\n",
    "# Assign to DataFrame\n",
    "df_subset['p1_career_wins_before'] = p1_career_wins_before\n",
    "df_subset['p2_career_wins_before'] = p2_career_wins_before\n",
    "df_subset['p1_career_wins_last3_pct_before'] = p1_career_wins_last3_pct_before\n",
    "df_subset['p2_career_wins_last3_pct_before'] = p2_career_wins_last3_pct_before\n",
    "df_subset['p1_career_wins_last5_pct_before'] = p1_career_wins_last5_pct_before\n",
    "df_subset['p2_career_wins_last5_pct_before'] = p2_career_wins_last5_pct_before\n",
    "df_subset['p1_career_wins_last10_pct_before'] = p1_career_wins_last10_pct_before\n",
    "df_subset['p2_career_wins_last10_pct_before'] = p2_career_wins_last10_pct_before"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_intelgpu3)",
   "language": "python",
   "name": "tf_intelgpu3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
